{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Local Differential Privacy\n",
    "\n",
    "As you can see, the basic sum query is not differentially private at all! In truth, differential privacy always requires a form of randomness added to the query. Let me show you what I mean.\n",
    "\n",
    "### Randomized Response (Local Differential Privacy)\n",
    "\n",
    "Let's say I have a group of people I wish to survey about a very taboo behavior which I think they will lie about (say, I want to know if they have ever committed a certain kind of crime). I'm not a policeman, I'm just trying to collect statistics to understand the higher level trend in society. So, how do we do this? One technique is to add randomness to each person's response by giving each person the following instructions (assuming I'm asking a simple yes/no question):\n",
    "\n",
    "- Flip a coin 2 times.\n",
    "- If the first coin flip is heads, answer honestly\n",
    "- If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)!\n",
    "\n",
    "Thus, each person is now protected with \"plausible deniability\". If they answer \"Yes\" to the question \"have you committed X crime?\", then it might becasue they actually did, or it might be becasue they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the \"true statistics\" are simply averaged with a 50% probability. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained. \n",
    "\n",
    "However, it should be noted that, especially when we only have a few samples, this comes at the cost of accuracy. This tradeoff exists across all of Differential Privacy. The greater the privacy protection (plausible deniability) the less accurate the results. \n",
    "\n",
    "Let's implement this local DP for our database before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParallelDB(db , removeIndex):\n",
    "    return(torch.cat((db[:removeIndex] , db[removeIndex+1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParallelDatabases(db):\n",
    "    parallelDatabases = []\n",
    "    for i in range(len(db)):\n",
    "        pdb = getParallelDB(db , i)\n",
    "        parallelDatabases.append(pdb)\n",
    "    \n",
    "    return parallelDatabases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_createDB_and_parallels(numOfEntries):\n",
    "    db = torch.rand(numOfEntries)>0.5\n",
    "    pdbs = getParallelDatabases(db)\n",
    "    return(db , pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueResult = torch.mean(db.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4900)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to noise our dataset with LocalDifferential Privacy and it is all about adding noise to the data itself\n",
    "# -\n",
    "So adding noise to data means replacing some of these values random values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstCoinFlip = (torch.rand(len(db)) > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstCoinFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondCoinFlip = (torch.rand(len(db)) > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondCoinFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 1st coinFlip is head(that means 1) we keep the values that are inthe database<br>\n",
    "So we can Multiply the database with firstCoinFlip<br>\n",
    "After we'll having 0 at the places tail occured<br>\n",
    "Now I can do (1 - firstCoinFlip) to interchange ones and zeroes and after I can multiply it with secondCoinFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.float() * firstCoinFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - firstCoinFlip) * secondCoinFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentedDatabase = db.float() * firstCoinFlip + (1-firstCoinFlip) * secondCoinFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.mean(augmentedDatabase.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (meanOfDatabase + actual)/2 = augemented\n",
    "# DeSkew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3800)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedResult = (m * 2) - 0.5\n",
    "augmentedResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    \n",
    "    trueResult = torch.mean(db.float())\n",
    "    \n",
    "    firstCoinFlip = (torch.rand(len(db)) > 0.5).float()\n",
    "    secondCoinFlip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmentedDatabase = db.float() * firstCoinFlip + ((1-firstCoinFlip) * secondCoinFlip)\n",
    "    \n",
    "    dbResult = torch.mean(augmentedDatabase.float()) * 2 - 0.5\n",
    "    \n",
    "    return dbResult , trueResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5200), tensor(0.4900))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.10000002384185791 And Without Noise 0.5\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(10)\n",
    "withNoise, withoutNoise = query(db)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.42000001668930054 And Without Noise 0.44999998807907104\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)\n",
    "withNoise, withoutNoise = query(db)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.5099999904632568 And Without Noise 0.5059999823570251\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(1000)\n",
    "withNoise, withoutNoise = query(db)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.5146000385284424 And Without Noise 0.4970000088214874\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(10000)\n",
    "withNoise, withoutNoise = query(db)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Varying Amounts of Noise\n",
    "\n",
    "In this project, I want you to augment the randomized response query (the one we just wrote) to allow for varying amounts of randomness to be added. Specifically, I want you to bias the coin flip to be higher or lower and then run the same experiment. \n",
    "\n",
    "Note - this one is a bit tricker than you might expect. You need to both adjust the likelihood of the first coin flip AND the de-skewing at the end (where we create the \"augmented_result\" variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueResult = torch.mean(db.float())\n",
    "    \n",
    "firstCoinFlip = (torch.rand(len(db)) > noise).float() #Biased coin\n",
    "secondCoinFlip = (torch.rand(len(db)) > 0.5).float()\n",
    "\n",
    "augmentedDatabase = db.float() * firstCoinFlip + ((1-firstCoinFlip) * secondCoinFlip)\n",
    "\n",
    "#There will change in DeSkewing\n",
    "skResult = torch.mean(augmentedDatabase.float()) \n",
    "\n",
    "#return dbResult , trueResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueMean = 0.7\n",
    "noiseMean = 0.5 #second coin flip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initially what we are doing is . . .\n",
    "augmentedMean = (trueMean + noiseMean)/2\n",
    "augmentedMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.5 #First coin\n",
    "#Which actually means 50% of the time we use trueMean and 50% of the time we use noiseMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentedMean = (trueMean*noise) + (noiseMean*(1 - noise))\n",
    "augmentedMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get trueMean from above equation by simple algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "privateResult = (skResult/noise) - ((0.5*(1-noise)) / noise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5056)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privateResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5028)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db, noise=0.2):\n",
    "    \n",
    "    trueResult = torch.mean(db.float())\n",
    "    \n",
    "    firstCoinFlip = (torch.rand(len(db)) > noise).float() #Biased coin\n",
    "    secondCoinFlip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmentedDatabase = db.float() * firstCoinFlip + ((1-firstCoinFlip) * secondCoinFlip)\n",
    "    \n",
    "    #There will change in DeSkewing\n",
    "    skResult = torch.mean(augmentedDatabase.float()) \n",
    "    \n",
    "    privateResult = (skResult/noise) - ((0.5*(1-noise))/noise)\n",
    "    return privateResult , trueResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.19999980926513672 And Without Noise 0.46000000834465027\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)\n",
    "withNoise, withoutNoise = query(db, noise=0.1)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.09999990463256836 And Without Noise 0.44999998807907104\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)\n",
    "withNoise, withoutNoise = query(db, noise=0.2)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.6000000238418579 And Without Noise 0.47999998927116394\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)\n",
    "withNoise, withoutNoise = query(db, noise=0.4)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.5374999642372131 And Without Noise 0.5600000023841858\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)\n",
    "withNoise, withoutNoise = query(db, noise=0.8)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise 0.5504999160766602 And Without Noise 0.5080000162124634\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = get_createDB_and_parallels(10000)\n",
    "withNoise, withoutNoise = query(db, noise=0.2)\n",
    "print(\"With Noise {} And Without Noise {}\".format(withNoise,withoutNoise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: The Formal Definition of Differential Privacy\n",
    "\n",
    "The previous method of adding noise was called \"Local Differentail Privacy\" because we added noise to each datapoint individually. This is necessary for some situations wherein the data is SO sensitive that individuals do not trust noise to be added later. However, it comes at a very high cost in terms of accuracy. \n",
    "\n",
    "However, alternatively we can add noise AFTER data has been aggregated by a function. This kind of noise can allow for similar levels of protection with a lower affect on accuracy. However, participants must be able to trust that no-one looked at their datapoints _before_ the aggregation took place. In some situations this works out well, in others (such as an individual hand-surveying a group of people), this is less realistic.\n",
    "\n",
    "Nevertheless, global differential privacy is incredibly important because it allows us to perform differential privacy on smaller groups of individuals with lower amounts of noise. Let's revisit our sum functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return torch.sum(db.float()) + noise\n",
    "#In localDP we would have done this return torch.sum(db.float() + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.5000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea here is that we want to add noise to the output of our function. We actually have two different kinds of noise we can add - Laplacian Noise or Gaussian Noise. However, before we do so at this point we need to dive into the formal definition of Differential Privacy.\n",
    "\n",
    "![alt text](dp_formula.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Image From: \"The Algorithmic Foundations of Differential Privacy\" - Cynthia Dwork and Aaron Roth - https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return torch.sum(db.float())\n",
    "\n",
    "def M(db):\n",
    "    query(db) + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M => is Randomised Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This definition does not _create_ differential privacy, instead it is a measure of how much privacy is afforded by a query M. Specifically, it's a comparison between running the query M on a database (x) and a parallel database (y). As you remember, parallel databases are defined to be the same as a full database (x) with one entry/person removed.\n",
    "\n",
    "Thus, this definition says that FOR ALL parallel databases, the maximum distance between a query on database (x) and the same query on database (y) will be e^epsilon, but that occasionally this constraint won't hold with probability delta. Thus, this theorem is called \"epsilon delta\" differential privacy.\n",
    "\n",
    "# Epsilon\n",
    "\n",
    "Let's unpack the intuition of this for a moment. \n",
    "\n",
    "Epsilon Zero: If a query satisfied this inequality where epsilon was set to 0, then that would mean that the query for all parallel databases outputed the exact same value as the full database. As you may remember, when we calculated the \"threshold\" function, often the Sensitivity was 0. In that case, the epsilon also happened to be zero.\n",
    "\n",
    "Epsilon One: If a query satisfied this inequality with epsilon 1, then the maximum distance between all queries would be 1 - or more precisely - the maximum distance between the two random distributions M(x) and M(y) is 1 (because all these queries have some amount of randomness in them, just like we observed in the last section).\n",
    "\n",
    "# Delta\n",
    "\n",
    "Delta is basically the probability that epsilon breaks. Namely, sometimes the epsilon is different for some queries than it is for others. For example, you may remember when we were calculating the sensitivity of threshold, most of the time sensitivity was 0 but sometimes it was 1. Thus, we could calculate this as \"epsilon zero but non-zero delta\" which would say that epsilon is perfect except for some probability of the time when it's arbitrarily higher. Note that this expression doesn't represent the full tradeoff between epsilon and delta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: How To Add Noise for Global Differential Privacy\n",
    "\n",
    "In this lesson, we're going to learn about how to take a query and add varying amounts of noise so that it satisfies a certain degree of differential privacy. In particular, we're going to leave behind the Local Differential privacy previously discussed and instead opt to focus on Global differential privacy. \n",
    "\n",
    "So, to sum up, this lesson is about adding noise to the output of our query so that it satisfies a certain epsilon-delta differential privacy threshold.\n",
    "\n",
    "There are two kinds of noise we can add - Gaussian Noise or Laplacian Noise. Generally speaking Laplacian is better, but both are still valid. Now to the hard question...\n",
    "\n",
    "### How much noise should we add?\n",
    "\n",
    "The amount of noise necessary to add to the output of a query is a function of four things:\n",
    "\n",
    "- the type of noise (Gaussian/Laplacian)\n",
    "- the sensitivity of the query/function\n",
    "- the desired epsilon (ε)\n",
    "- the desired delta (δ)\n",
    "\n",
    "Thus, for each type of noise we're adding, we have different way of calculating how much to add as a function of sensitivity, epsilon, and delta. We're going to focus on Laplacian noise. Laplacian noise is increased/decreased according to a \"scale\" parameter b. We choose \"b\" based on the following formula.\n",
    "\n",
    "b = sensitivity(query) / epsilon\n",
    "\n",
    "In other words, if we set b to be this value, then we know that we will have a privacy leakage of <= epsilon. Furthermore, the nice thing about Laplace is that it guarantees this with delta == 0. There are some tunings where we can have very low epsilon where delta is non-zero, but we'll ignore them for now.\n",
    "\n",
    "### Querying Repeatedly\n",
    "\n",
    "- if we query the database multiple times - we can simply add the epsilons (Even if we change the amount of noise and their epsilons are not the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Create a Differentially Private Query\n",
    "\n",
    "In this project, I want you to take what you learned in the previous lesson and create a query function which sums over the database and adds just the right amount of noise such that it satisfies an epsilon constraint. Write a query for both \"sum\" and for \"mean\". Ensure that you use the correct sensitivity measures for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5 # if we decrease this we are actually incresing the amount of noise to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = get_createDB_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(53, dtype=torch.uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(db)#Max sensitivity can be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2,\n",
       "        2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "        2, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*db #Max sensitivity will be 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets jump into query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacianMechanism(db, query, sensitivity):\n",
    "    \n",
    "    beta = sensitivity / epsilon\n",
    "    \n",
    "    noise = torch.tensor(np.random.laplace(0,beta,1)) #Mean centered at zero and beta is controlling the spread\n",
    "    return query(db) + noise#GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53.2056], dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacianMechanism(db, sum_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(53)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueSum = db.sum()\n",
    "trueSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets do this for mean query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_query(db):\n",
    "    return torch.mean(db.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think what can be the sensitivity <br>\n",
    "Max change divided by total number of entries i.e. 1/len(db) in our case => 1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5401], dtype=torch.float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacianMechanism(db, mean_query, 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueMean = torch.mean(db.float())\n",
    "trueMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
