{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Toy Federated Learning\n",
    "\n",
    "Let's start by training a toy model the centralized way. This is about a simple as models get. We first need:\n",
    "\n",
    "- a toy dataset\n",
    "- a model\n",
    "- some basic training logic for training a model to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch as t\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "data = t.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
    "target = t.tensor([[1.],[1], [0], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4635)\n",
      "tensor(1.4612)\n",
      "tensor(0.9495)\n",
      "tensor(0.6264)\n",
      "tensor(0.4157)\n",
      "tensor(0.2775)\n",
      "tensor(0.1863)\n",
      "tensor(0.1259)\n",
      "tensor(0.0857)\n",
      "tensor(0.0587)\n",
      "tensor(0.0406)\n",
      "tensor(0.0283)\n",
      "tensor(0.0198)\n",
      "tensor(0.0140)\n",
      "tensor(0.0100)\n",
      "tensor(0.0072)\n",
      "tensor(0.0052)\n",
      "tensor(0.0038)\n",
      "tensor(0.0028)\n",
      "tensor(0.0020)\n"
     ]
    }
   ],
   "source": [
    "def train(iterations=20):\n",
    "    for iter in range(iterations):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        print(loss.data)\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make this federated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Split our data into different pieces and send it to different workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBob = data[0:2].send(bob)\n",
    "targetBob = target[0:2].send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAlice = data[2:].send(alice)\n",
    "targetAlice = data[2:].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(dataBob, targetBob), (dataAlice, targetAlice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((Wrapper)>[PointerTensor | me:14174892603 -> bob:18445251651],\n",
       "  (Wrapper)>[PointerTensor | me:65993074018 -> bob:26123144840]),\n",
       " ((Wrapper)>[PointerTensor | me:3088829396 -> alice:51536374223],\n",
       "  (Wrapper)>[PointerTensor | me:47895075561 -> alice:57108677266]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0], datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,1)\n",
    "opt = optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1911,  0.4588]], requires_grad=True), Parameter containing:\n",
       " tensor([0.7054], requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data, _target = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:14174892603 -> bob:18445251651]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:bob #objects:2>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Send model to data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.send(_data.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " Parameter>[PointerTensor | me:16205244331 -> bob:97595607239],\n",
       " Parameter containing:\n",
       " Parameter>[PointerTensor | me:57844515130 -> bob:24379998427]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())#notice the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ((pred - _target)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:94555604377 -> bob:93410575903]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. Get model back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0277, requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations=20):\n",
    "\n",
    "    model = nn.Linear(2,1)\n",
    "    opt = optim.SGD(params=model.parameters(), lr=0.1)\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "\n",
    "        for _data, _target in datasets:\n",
    "\n",
    "            # send model to the data\n",
    "            model = model.send(_data.location)\n",
    "\n",
    "            # do normal training\n",
    "            opt.zero_grad()\n",
    "            pred = model(_data)\n",
    "            loss = ((pred - _target)**2).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # get smarter model back\n",
    "            model = model.get()\n",
    "\n",
    "            print(loss.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2696, requires_grad=True)\n",
      "tensor(2.9203, requires_grad=True)\n",
      "tensor(1.3898, requires_grad=True)\n",
      "tensor(1.1896, requires_grad=True)\n",
      "tensor(0.4829, requires_grad=True)\n",
      "tensor(0.7953, requires_grad=True)\n",
      "tensor(0.1853, requires_grad=True)\n",
      "tensor(0.6528, requires_grad=True)\n",
      "tensor(0.0863, requires_grad=True)\n",
      "tensor(0.5978, requires_grad=True)\n",
      "tensor(0.0551, requires_grad=True)\n",
      "tensor(0.5739, requires_grad=True)\n",
      "tensor(0.0470, requires_grad=True)\n",
      "tensor(0.5615, requires_grad=True)\n",
      "tensor(0.0467, requires_grad=True)\n",
      "tensor(0.5540, requires_grad=True)\n",
      "tensor(0.0486, requires_grad=True)\n",
      "tensor(0.5489, requires_grad=True)\n",
      "tensor(0.0511, requires_grad=True)\n",
      "tensor(0.5451, requires_grad=True)\n",
      "tensor(0.0534, requires_grad=True)\n",
      "tensor(0.5422, requires_grad=True)\n",
      "tensor(0.0554, requires_grad=True)\n",
      "tensor(0.5400, requires_grad=True)\n",
      "tensor(0.0570, requires_grad=True)\n",
      "tensor(0.5382, requires_grad=True)\n",
      "tensor(0.0584, requires_grad=True)\n",
      "tensor(0.5369, requires_grad=True)\n",
      "tensor(0.0595, requires_grad=True)\n",
      "tensor(0.5358, requires_grad=True)\n",
      "tensor(0.0604, requires_grad=True)\n",
      "tensor(0.5350, requires_grad=True)\n",
      "tensor(0.0611, requires_grad=True)\n",
      "tensor(0.5343, requires_grad=True)\n",
      "tensor(0.0616, requires_grad=True)\n",
      "tensor(0.5338, requires_grad=True)\n",
      "tensor(0.0621, requires_grad=True)\n",
      "tensor(0.5334, requires_grad=True)\n",
      "tensor(0.0624, requires_grad=True)\n",
      "tensor(0.5331, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
