{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as t\n",
    "hook = sy.TorchHook(t)\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook,id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook,id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(hook,id=\"secure_worker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:syft.workers.base:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:secure_worker #objects:0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob.add_workers([alice, secure_worker])\n",
    "alice.add_workers([bob, secure_worker])\n",
    "secure_worker.add_workers([bob, alice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy Dataset\n",
    "data = t.tensor([[0,0],[0,1],[1,0],[1,1.]],requires_grad=True)\n",
    "target = t.tensor([[0],[0],[1],[1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending data to workers\n",
    "bobData = data[:2].send(bob)\n",
    "bobTarget = target[2:].send(bob)\n",
    "\n",
    "aliceData = data[2:].send(alice)\n",
    "aliceTarget = target[2:].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise a toy model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobModel = model.copy().send(bob)\n",
    "aliceModel = model.copy().send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diff workers diff models diff optimizers\n",
    "bobOpt = optim.SGD(params=bobModel.parameters() , lr=0.1)\n",
    "aliceOpt = optim.SGD(params=aliceModel.parameters() , lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4647)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bobOpt.zero_grad()\n",
    "bobPred = bobModel(bobData)\n",
    "bobLoss = ((bobPred - bobTarget) ** 2).sum()\n",
    "bobLoss.backward()\n",
    "\n",
    "bobOpt.step()\n",
    "bobLoss = bobLoss.get().data\n",
    "bobLoss\n",
    "#run this cell again & again u'll observe loss's going down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliceOpt.zero_grad()\n",
    "alicePred = aliceModel(aliceData)\n",
    "aliceLoss = ((alicePred - aliceTarget) ** 2).sum()\n",
    "aliceLoss.backward()\n",
    "\n",
    "aliceOpt.step()\n",
    "aliceLoss = aliceLoss.get().data\n",
    "aliceLoss\n",
    "#run this cell again & again u'll observe loss's going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob Loss: 0.002106368774548173 \t Alice Loss: 0.0006552091799676418\n",
      "Bob Loss: 0.001269206521101296 \t Alice Loss: 0.0002336803008802235\n",
      "Bob Loss: 0.0004387546214275062 \t Alice Loss: 7.13843764970079e-05\n",
      "Bob Loss: 0.00016431546828243881 \t Alice Loss: 7.575537892989814e-06\n",
      "Bob Loss: 7.452676072716713e-05 \t Alice Loss: 5.521442858480441e-09\n",
      "Bob Loss: 4.05733662773855e-05 \t Alice Loss: 9.931389968187432e-07\n",
      "Bob Loss: 2.525991112634074e-05 \t Alice Loss: 1.7968086467590183e-06\n",
      "Bob Loss: 1.7116466551669873e-05 \t Alice Loss: 1.8905408296632231e-06\n",
      "Bob Loss: 1.2177690223325044e-05 \t Alice Loss: 1.6573189896007534e-06\n",
      "Bob Loss: 8.897986845113337e-06 \t Alice Loss: 1.3427068097371375e-06\n"
     ]
    }
   ],
   "source": [
    "for round_iter in range(10):\n",
    "    \n",
    "    bobModel = model.copy().send(bob)\n",
    "    aliceModel = model.copy().send(alice)\n",
    "    \n",
    "    bobOpt = optim.SGD(params=bobModel.parameters() , lr=0.1)\n",
    "    aliceOpt = optim.SGD(params=aliceModel.parameters() , lr=0.1)\n",
    "    \n",
    "    #Epochs\n",
    "    for i in range(10):\n",
    "        bobOpt.zero_grad()\n",
    "        bobPred = bobModel(bobData)\n",
    "        bobLoss = ((bobPred - bobTarget) ** 2).sum()\n",
    "        bobLoss.backward()\n",
    "        \n",
    "        bobOpt.step()\n",
    "        bobLoss = bobLoss.get().data\n",
    "        bobLoss\n",
    "        \n",
    "        aliceOpt.zero_grad()\n",
    "        alicePred = aliceModel(aliceData)\n",
    "        aliceLoss = ((alicePred - aliceTarget) ** 2).sum()\n",
    "        aliceLoss.backward()\n",
    "        \n",
    "        aliceOpt.step()\n",
    "        aliceLoss = aliceLoss.get().data\n",
    "        aliceLoss\n",
    "        \n",
    "    #Here comes the role of our secure_worker\n",
    "    #Trusted Aggregator\n",
    "    \n",
    "    aliceModel.move(secure_worker)\n",
    "    bobModel.move(secure_worker)\n",
    "    \n",
    "    with t.no_grad():\n",
    "        #Weight Aggregation while they are with Trusted aggregator\n",
    "        model.weight.set_(((aliceModel.weight.data + bobModel.weight.data) / 2).get())\n",
    "\n",
    "        #Bias Aggregation while they are with Trusted aggregator\n",
    "        model.bias.set_(((aliceModel.bias.data + bobModel.bias.data) / 2).get())\n",
    "    \n",
    "    print('Bob Loss: {} \\t Alice Loss: {}'.format(bobLoss,aliceLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
